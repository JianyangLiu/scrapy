import multiprocessing as mp
import time
from urllib.request import urlopen, urljoin
from bs4 import BeautifulSoup
import re

base_url = "https://www.stateofthedapps.com/rankings?page=2"
def crawl(url):
    response = urlopen(url)
                # slightly delay for downloading
    return response.read().decode()
    domain_urls=set([urljoin("https://www.stateofthedapps.com/","rankings?page="+str(i)) for i in range(1,20)])
i=0
for domain_url in domain_urls:
    i+=1
    print(i)
    print(domain_url)
    html1=crawl(domain_url)
    soup = BeautifulSoup(html1, 'lxml')
    urls = soup.find_all('a', {"href": re.compile('/dapps/*')})
    page_urls = set([urljoin(base_url, url['href']) for url in urls])
    page_urls.remove('https://www.stateofthedapps.com/dapps/submit/new')
    page_urls.remove('https://www.stateofthedapps.com/dapps')
    for url in page_urls:
        html=crawl(url)
        soup = BeautifulSoup(html, 'lxml')
        m=soup.find(True,{"itemprop":["name"]}).get_text()
        a=soup.find(True,{"class":["description"]}).get_text()
        b=soup.find(True,{"class":["component-DappDetailBodyContentModulesStatus"]}).get_text()
        c=soup.find(True,{"class":["author-data"]}).get_text()
        d=soup.find(True,{"class":["license-data"]}).get_text()
        e=soup.find(True,{"class":["component-DappDetailBodyContentModulesSubmitted"]}).get_text()      
        f=soup.find(True,{"class":["component-DappDetailBodyContentModulesUpdated"]}).get_text() 
        g=soup.find(True,{"class":["category-item"]}).get_text()
        
        print("Name:",m)
        print("Description:",a,b)
        print('')
        print("Author:",c)
        print("License:",d)
        print(e,f)
        print("Category:",g)
        print('')
